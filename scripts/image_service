#!/usr/bin/env python3
## Simple image processing demo 

import rospy
from std_msgs.msg import String
from prior4_ros_container.srv import ImageService,ImageServiceResponse
from sensor_msgs.msg import RegionOfInterest
from geometry_msgs.msg import Pose

from cv_bridge import CvBridge, CvBridgeError
import cv2

from Prior4PE.Prior4 import *
from Prior4PE import PriorDecl
from scipy.spatial.transform import Rotation

import tf as ros_tf

# listener = None

def shutdown_hook():
  print("Shutting down node")

pose_estimation = Prior4({
  "data_path": '/home/catkin_ws/python_src/prior4_detection/',
  "verbose": 10
})

def handle_service_request(req):
    """This method is called when a service request is received"""
    print("Received image processing request")
    print(req.description.data)
    # print(req) # if you want to output the full result

    # Load data from service request
    ros_rgb_image   = req.rgb
    ros_depth_image = req.depth
    description     = req.description.data

    # Convert images to openCV
    cv_rgb_image   = None
    cv_depth_image = None
    bridge = CvBridge()
    try:
      # cv_rgb_image = bridge.imgmsg_to_cv2(ros_rgb_image, encoding = "passthrough")
      # cv_depth_image = bridge.imgmsg_to_cv2(ros_depth_image, encoding = "passthrough")
      cv_rgb_image = bridge.imgmsg_to_cv2(ros_rgb_image)
      cv_depth_image = bridge.imgmsg_to_cv2(ros_depth_image)
    except CvBridgeError as e:
      print(e)
      return
    (rows,cols,channels) = cv_rgb_image.shape
    print(f'RGB image parameters (rows,cols,channels,pixels,type): {rows}, {cols}, {channels}, {cv_rgb_image.size}, {cv_rgb_image.dtype}')
    (rows,cols) = cv_depth_image.shape
    print(f'Depth image parameters (rows,cols,pixels,type): {rows}, {cols}, {cv_depth_image.size}, {cv_depth_image.dtype}')

    # Write out the images for testing purposes
    print(cv2.imwrite("/home/catkin_ws/src/prior4_ros_container/rgb_out.png", cv_rgb_image))
    print(cv2.imwrite("/home/catkin_ws/src/prior4_ros_container/depth_out.png", cv_depth_image))


    (ulp_trans, ulp_rot) = listener.lookupTransform("head_mount_kinect_rgb_optical_frame", "dishwasher/upper_left_plates", rospy.Time(0))
    (ulpv_trans, ulpv_rot) = listener.lookupTransform("head_mount_kinect_rgb_optical_frame", "dishwasher/upper_left_plates_vert", rospy.Time(0))

    (lfp_trans, lfp_rot) = listener.lookupTransform("head_mount_kinect_rgb_optical_frame", "dishwasher/lower_front_plates", rospy.Time(0))
    (lfpv_trans, lfpv_rot) = listener.lookupTransform("head_mount_kinect_rgb_optical_frame", "dishwasher/lower_front_plates_vert", rospy.Time(0))

    print("Looked up transform: ")
    print(ulp_trans)
    print(ulp_rot)

#Example:
#     [0.0409228400354783, 0.27642242629640124, 1.4659930943695996]
# [-0.37528362803883986, -0.8220588219169078, 0.38714850180600885, -0.1830233028440747]

    prior = PriorDecl.examplePrior
    prior["countOfPriors"] = 2
    prior["informationPerPrior"] = 3

    prior["planeRotation"] = [Rotation.from_quat(ulp_rot)] + [Rotation.from_quat(ulpv_rot)] * 2 + [Rotation.from_quat(lfp_rot)] + [Rotation.from_quat(lfpv_rot)] * 2
    prior["planeTranslation"] = [np.array(ulp_trans)] + [np.array(ulpv_trans)] * 2 + [np.array(lfp_trans)] + [np.array(lfpv_trans)] * 2

    prior["point"] = np.array([0,0,0, 0,0,0, 0,0,1000] * 2).reshape(1, prior["countOfPriors"], prior["informationPerPrior"], 3)
    prior["pointd"] = np.array([0] * 2 * 3).reshape(1, prior["countOfPriors"], prior["informationPerPrior"], )

    prior["pointw"] = np.array([1./30., 0., 0.] * 2).reshape(1, prior["countOfPriors"], prior["informationPerPrior"], )

    print('prior', prior)


    ##################################
    # Here you can call your code to #
    # analyze the image              #
    ##################################

    rgb_image = np.stack([cv_rgb_image[...,-1],cv_rgb_image[...,-2],cv_rgb_image[...,-3]], axis=-1)
    # priors = PriorDecl.prepare_prior(PriorDecl.examplePrior)\

    priors = PriorDecl.prepare_prior(prior)
    pose_outputs, bbs, label_image = pose_estimation(rgb_image, cv_depth_image, priors=priors)

    #################################
    # Creating the service response #
    #################################
    response = ImageServiceResponse()
    response.success = True

    # x,y, height, width, (do_rectify)
    response.bounding_boxes = [RegionOfInterest(max(0,int(bb[0] - bb[2]/2)*2), max(0,int(bb[1] - bb[3]/2)*2), int(bb[2])*2, int(bb[3])*2,False) for bb in bbs]#[RegionOfInterest(1,2,3,4,False)]

    response.class_ids = [po[0].argmax() * 2 for po in pose_outputs]#[0,1]

    #if plate and big then declare so
    for j, cid in enumerate(response.class_ids):
      print('pose_outputs[j][2][0,4:4+prior["countOfPriors"]*2].argmin()', pose_outputs[j][2][0,4:4+prior["countOfPriors"]*2].argmin())
      if cid < 2 and pose_outputs[j][2][0,4:4+prior["countOfPriors"]*2].argmin() >= prior["countOfPriors"]:
        response.class_ids[j] += 1

    response.class_confidences = [1.0 / (po[2][0,4:4+prior["countOfPriors"]*2] if po[0].argmax() < 1 else po[2][0,4:4+prior["countOfPriors"]]).min() for po in pose_outputs]

    # TODO insert your own openCV mat here that you want to return
    ros_segmentation_image = bridge.cv2_to_imgmsg(255*(label_image > 0).astype(np.uint8)[...,np.newaxis], encoding="passthrough")
    response.segmentation_mask = ros_segmentation_image

    # Instantiate and fill a pose
    rgb_poses_with_prior = [po[1][0,4+(po[2][0,4:4+prior["countOfPriors"]*2] if po[0].argmax() < 1 else po[2][0,4:4+prior["countOfPriors"]]).argmin()] for po in pose_outputs]


    rgbd_poses_with_prior = [po[1][0,4+(po[2][0,4+prior["countOfPriors"]*2:4+prior["countOfPriors"]*4] if po[0].argmax() < 1 else po[2][0,4+prior["countOfPriors"]*2:4+prior["countOfPriors"]*3]).argmin()] for po in pose_outputs]

    rgb_poses = [po[1][0,0] for po in pose_outputs]
    rgbd_poses = [po[1][0,2] for po in pose_outputs]
    
    poses_res = [] #[Pose(p[:3,3], Rotation.from_matrix(p[:3,:3]).as_quat()) for p in rgb_poses_with_prior]
    for pose in rgb_poses_with_prior:
    # for pose in rgb_poses:
    # for pose in rgbd_poses:
      t = pose[:3,3]/1000
      R_quat = Rotation.from_matrix(pose[:3,:3]).as_quat()

      p = Pose()
      p.position.x = t[0]
      p.position.y = t[1]
      p.position.z = t[2]
      p.orientation.x = R_quat[0]
      p.orientation.y = R_quat[1]
      p.orientation.z = R_quat[2]
      p.orientation.w = R_quat[-1]

      poses_res.append(p)
    
    # p1 = Pose()
    # p1.position.x = 1
    # p1.position.y = 2
    # p1.position.z = 3
    # p1.orientation.x = 1
    # p1.orientation.y = 2
    # p1.orientation.z = 3
    # p1.orientation.w = 4

    response.pose_results = poses_res
    return response

def image_service_server():
    # pub = rospy.Publisher('chatter', String, queue_size=10)
    rospy.init_node('image_service_node')
    s = rospy.Service('image_service', ImageService, handle_service_request)
    global listener
    listener = ros_tf.TransformListener()

    rospy.on_shutdown(shutdown_hook)
    print("Ready to accept image processing requests")
    rospy.spin()

    # hello_str = "hello world %s" % rospy.get_time()
    # rospy.loginfo(hello_str)
    

if __name__ == '__main__':
    try:
        image_service_server()
    except rospy.ROSInterruptException:
        pass
